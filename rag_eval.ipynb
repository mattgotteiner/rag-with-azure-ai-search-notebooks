{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate RAG answer quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup API clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import azure.identity\n",
    "import dotenv\n",
    "import openai\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "azure_credential = azure.identity.AzureDeveloperCliCredential(tenant_id=os.getenv(\"AZURE_TENANT_ID\"))\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "AZURE_OPENAI_SERVICE = os.getenv(\"AZURE_OPENAI_SERVICE\")\n",
    "AZURE_OPENAI_ADA_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_ADA_DEPLOYMENT\")\n",
    "\n",
    "token_provider = azure.identity.get_bearer_token_provider(azure_credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "openai_client = openai.AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    azure_ad_token_provider=token_provider)\n",
    "\n",
    "def get_embedding(text):\n",
    "    get_embeddings_response = openai_client.embeddings.create(model=AZURE_OPENAI_ADA_DEPLOYMENT, input=text)\n",
    "    return get_embeddings_response.data[0].embedding\n",
    "\n",
    "# Initialize Azure search client\n",
    "AZURE_SEARCH_SERVICE = os.getenv(\"AZURE_SEARCH_SERVICE\")\n",
    "AZURE_SEARCH_ENDPOINT = f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\"\n",
    "\n",
    "AZURE_SEARCH_FULL_INDEX = \"gptkbindex\"\n",
    "search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_FULL_INDEX, credential=azure_credential)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get answer for a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Manager of Sales is responsible for leading, managing, and motivating the sales team to exceed sales objectives and targets. This includes developing and implementing successful sales strategies, analyzing sales and market data, maintaining relationships with key customers and vendors, monitoring sales team performance, managing the sales budget, and addressing customer inquiries and complaints [role_library-23.pdf][role_library-24.pdf].\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What does a sales manager do?\"\n",
    "user_question_vector = get_embedding(user_question)\n",
    "\n",
    "r = search_client.search(\n",
    "        user_question,\n",
    "        top=5, \n",
    "        vector_queries=[\n",
    "                VectorizedQuery(vector=user_question_vector, k_nearest_neighbors=50, fields=\"embedding\")],\n",
    "        query_type=\"semantic\",\n",
    "        semantic_configuration_name=\"default\")\n",
    "\n",
    "sources = \"\\n\\n\".join([f\"[{doc['sourcepage']}]: {doc['content']}\\n\" for doc in r])\n",
    "\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "Assistant helps company employees questions about the employee handbook. Be brief in your answers.\n",
    "Answer ONLY with the facts listed in the list of sources below.\n",
    "If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below.\n",
    "Each source has a name followed by colon and the actual information, include the source name for each fact you use.\n",
    "Use square brackets to reference the source, for example [info1.txt].\n",
    "\"\"\"\n",
    "USER_MESSAGE = user_question + \"\\nSources: \" + sources\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": USER_MESSAGE},\n",
    "    ],\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the answer quality\n",
    "\n",
    "We can use the `azure-ai-evaluation` package to run GPT-based evaluators on the RAG responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 5.0, 'gpt_relevance': 5.0, 'relevance_reason': 'The response fully addresses the query with accurate and complete information about the role of a sales manager, including additional insights into their responsibilities and tasks.'}\n",
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The RESPONSE is fully grounded in the CONTEXT, accurately conveying all essential responsibilities of the Manager of Sales role without adding unsupported details or omitting critical points.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration, GroundednessEvaluator, RelevanceEvaluator\n",
    "\n",
    "model_config: AzureOpenAIModelConfiguration = {\n",
    "    \"azure_endpoint\": f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\",\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "}\n",
    "\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "\n",
    "relevance_score = relevance_eval(\n",
    "    query=user_question,\n",
    "    response=answer,\n",
    "    context=sources,\n",
    ")\n",
    "print(relevance_score)\n",
    "\n",
    "# If you see NaN, make sure you're using a GPT-4 level model\n",
    "groundedness_score = groundedness_eval(\n",
    "    response=answer,\n",
    "    context=sources,\n",
    ")\n",
    "print(groundedness_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
